{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load environment variables from the .env file\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mload_dotenv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp_chatbot_venv/lib/python3.13/site-packages/dotenv/main.py:346\u001b[0m, in \u001b[0;36mload_dotenv\u001b[0;34m(dotenv_path, stream, verbose, override, interpolate, encoding)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse a .env file and then load all the variables found as environment variables.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m.env file.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dotenv_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 346\u001b[0m     dotenv_path \u001b[38;5;241m=\u001b[39m \u001b[43mfind_dotenv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m dotenv \u001b[38;5;241m=\u001b[39m DotEnv(\n\u001b[1;32m    349\u001b[0m     dotenv_path\u001b[38;5;241m=\u001b[39mdotenv_path,\n\u001b[1;32m    350\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    355\u001b[0m )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dotenv\u001b[38;5;241m.\u001b[39mset_as_environment_variables()\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp_chatbot_venv/lib/python3.13/site-packages/dotenv/main.py:296\u001b[0m, in \u001b[0;36mfind_dotenv\u001b[0;34m(filename, raise_error_if_not_found, usecwd)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(main, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m usecwd \u001b[38;5;129;01mor\u001b[39;00m _is_interactive() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(sys, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrozen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# Should work without __file__, e.g. in REPL or IPython notebook.\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# will work for .py files\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     frame \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kb.AN_KnowledgeBase import KnowledgeBaseManager\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmos_account_name_full = \"https://fyp-chatbot-storage.mongo.cosmos.azure.com:443\"\n",
    "cosmos_account_name = \"fyp-chatbot-storage\"\n",
    "cosmos_account_key = \"sg6JwCvMNJumXadhLiKXoTrlF0piKBIYxTD71cn5sfbgWBdUJiRNd0dIndcZy2wVVHvkHzcd1tgXACDbjMscBA==\"\n",
    "cosmos_database_id = \"qnaDatabase\"\n",
    "\n",
    "cosmosdb_connection_string = \"mongodb://fyp-chatbot-storage:sg6JwCvMNJumXadhLiKXoTrlF0piKBIYxTD71cn5sfbgWBdUJiRNd0dIndcZy2wVVHvkHzcd1tgXACDbjMscBA==@fyp-chatbot-storage.mongo.cosmos.azure.com:10255/?ssl=true&replicaSet=globaldb&retrywrites=false&maxIdleTimeMS=120000&appName=@fyp-chatbot-storage@\"\n",
    "connection_string = f\"AccountEndpoint=https://{cosmos_account_name}.documents.azure.com;AccountKey={cosmos_account_key};Database={cosmos_database_id};ApiKind=MongoDb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "\n",
    "# Create a data source \n",
    "indexer_client = SearchIndexerClient(\n",
    "                os.environ.get(\"AZURE_AI_SEARCH_ENDPOINT\"),\n",
    "                AzureKeyCredential(os.environ.get(\"AZURE_AI_SEARCH_API_KEY\")),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"fyp-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source 'asknarelle-questions-and-answers-mongodb' created or updated\n"
     ]
    }
   ],
   "source": [
    "# create data source\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection\n",
    ")\n",
    "\n",
    "data_source_name = \"asknarelle-questions-and-answers-mongodb\"\n",
    "container = SearchIndexerDataContainer(name=\"questions\")\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=data_source_name,\n",
    "    type=\"cosmosdb\",\n",
    "    connection_string=connection_string,\n",
    "    container=container,\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qna-to-rag-ss-2 created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    EntityRecognitionSkill,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset,\n",
    "    CognitiveServicesAccountKey\n",
    ")\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = \"qna-to-rag-ss-2\"\n",
    "\n",
    "split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    context=\"/document\",  \n",
    "    maximum_page_length=2000,  \n",
    "    page_overlap_length=500,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/answer\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    resource_url=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),  \n",
    "    deployment_name=\"text-embedding-3-large\",  \n",
    "    model_name=\"text-embedding-3-large\",\n",
    "    dimensions=1536,\n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")  \n",
    "    ],  \n",
    ")\n",
    "  \n",
    "index_projections = SearchIndexerIndexProjection(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"parentId\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(name=\"content\", source=\"/document/pages/*\"),  \n",
    "                InputFieldMappingEntry(name=\"content_vector\", source=\"/document/pages/*/text_vector\"),\n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),  \n",
    "            ],  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ") \n",
    "\n",
    "# cognitive_services_account = CognitiveServicesAccountKey(key=AZURE_AI_MULTISERVICE_KEY)\n",
    "\n",
    "skills = [split_skill, embedding_skill]\n",
    "\n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generate embeddings\",  \n",
    "    skills=skills,  \n",
    "    index_projection=index_projections,\n",
    "    # cognitive_services_account=cognitive_services_account\n",
    ")\n",
    "  \n",
    "\n",
    "indexer_client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexer_result: {'additional_properties': {'@odata.context': 'https://fyp-chatbot-bernkjy.search.windows.net/$metadata#indexers/$entity'}, 'name': 'qna-storage-indexer-2', 'description': 'Indexer to index list of questions and answers', 'data_source_name': 'asknarelle-questions-and-answers-mongodb', 'skillset_name': 'qna-to-rag-ss-2', 'target_index_name': 'fyp-test', 'schedule': None, 'parameters': None, 'field_mappings': [<azure.search.documents.indexes._generated.models._models_py3.FieldMapping object at 0x12c4ba170>, <azure.search.documents.indexes._generated.models._models_py3.FieldMapping object at 0x12c5f9eb0>], 'output_field_mappings': [], 'is_disabled': False, 'e_tag': '\"0x8DD3087600E160F\"', 'encryption_key': None}\n",
      " qna-storage-indexer-2 is created and running. Give the indexer a few minutes before running a query.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    FieldMapping\n",
    ")\n",
    "\n",
    "# Create an indexer  \n",
    "indexer_name = \"qna-storage-indexer-2\"\n",
    "\n",
    "indexer_parameters = None\n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index list of questions and answers\", \n",
    "    skillset_name=skillset.name,\n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name, \n",
    "    field_mappings=[\n",
    "        FieldMapping(source_field_name=\"id\", target_field_name=\"id\"),\n",
    "        FieldMapping(source_field_name=\"question\", target_field_name=\"title\"),\n",
    "        FieldMapping(source_field_name=\"answer\",)\n",
    "    ],\n",
    "    parameters=indexer_parameters\n",
    ")  \n",
    "\n",
    "\n",
    "# Create and run the indexer   \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "\n",
    "print(f'indexer_result: {indexer_result}')\n",
    "\n",
    "print(f' {indexer_name} is created and running. Give the indexer a few minutes before running a query.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_client.run_indexer(indexer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qna-to-rag-ss created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    SearchIndexerSkillset,\n",
    "    CognitiveServicesAccountKey,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode\n",
    ")\n",
    "\n",
    "# Create a skillset\n",
    "skillset_name = \"qna-to-rag-ss\"\n",
    "\n",
    "split_skill = SplitSkill(\n",
    "    description=\"Split skill to chunk documents\",\n",
    "    text_split_mode=\"pages\",\n",
    "    context=\"/document\",\n",
    "    maximum_page_length=2000,\n",
    "    page_overlap_length=500,\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/question\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(\n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",\n",
    "    resource_url=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment_name=\"text-embedding-3-large\",\n",
    "    model_name=\"text-embedding-3-large\",\n",
    "    dimensions=1536,\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "index_projections = SearchIndexerIndexProjection(\n",
    "    selectors=[\n",
    "        SearchIndexerIndexProjectionSelector(\n",
    "            target_index_name=\"fyp-test\",\n",
    "            parent_key_field_name=\"parentId\",\n",
    "            source_context=\"/document/pages/*\",\n",
    "            mappings=[\n",
    "                InputFieldMappingEntry(name=\"content\", source=\"/document/pages/*\"),\n",
    "                InputFieldMappingEntry(name=\"content_vector\", source=\"/document/pages/*/text_vector\"),\n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    parameters=SearchIndexerIndexProjectionsParameters(\n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS\n",
    "    ),\n",
    ")\n",
    "\n",
    "skills = [split_skill, embedding_skill]\n",
    "\n",
    "skillset = SearchIndexerSkillset(\n",
    "    name=skillset_name,\n",
    "    description=\"Skillset to chunk documents and generate embeddings\",\n",
    "    skills=skills,\n",
    "    index_projection=index_projections,\n",
    "    # cognitive_services_account=CognitiveServicesAccountKey(key=AZURE_AI_MULTISERVICE_KEY)\n",
    ")\n",
    "\n",
    "indexer_client.create_or_update_skillset(skillset)\n",
    "print(f\"{skillset.name} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qna-indexer created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerDataSourceType,\n",
    "    SearchIndexerSkillset,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode\n",
    ")\n",
    "\n",
    "\n",
    "# Define data source\n",
    "data_source_name = \"asknarelle-questions-and-answers-mongodb\"\n",
    "container = SearchIndexerDataContainer(name=\"questions\")\n",
    "# data_source_connection = SearchIndexerDataSourceConnection(\n",
    "#     name=data_source_name,\n",
    "#     type=\"cosmosdb\",\n",
    "#     connection_string=connection_string,\n",
    "#     container=container,\n",
    "# )\n",
    "\n",
    "\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=data_source_name,\n",
    "    type=\"cosmosdb\",\n",
    "    connection_string=os.environ.get(\"COSMOSDB_CONNECTION_STRING\"),\n",
    "    container=container\n",
    ")\n",
    "\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "# index_projections = SearchIndexerIndexProjection(\n",
    "#     selectors=[\n",
    "#         SearchIndexerIndexProjectionSelector(\n",
    "#             target_index_name=index_name,\n",
    "#             parent_key_field_name=\"parentId\",\n",
    "#             source_context=\"/document/pages/*\",\n",
    "#             mappings=[\n",
    "#                 InputFieldMappingEntry(name=\"content\", source=\"/document/pages/*\"),\n",
    "#                 InputFieldMappingEntry(name=\"content_vector\", source=\"/document/pages/*/text_vector\"),\n",
    "#                 InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),\n",
    "#             ],\n",
    "#         ),\n",
    "#     ],\n",
    "#     parameters=SearchIndexerIndexProjectionsParameters(\n",
    "#         projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "indexer = SearchIndexer(\n",
    "    name=\"qna-indexer\",\n",
    "    data_source_name=data_source_connection.name,\n",
    "    target_index_name=\"fyp-test\",\n",
    "    skillset_name=skillset_name,\n",
    ")\n",
    "\n",
    "indexer_client.create_or_update_indexer(indexer)\n",
    "print(f\"{indexer.name} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp_chatbot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
